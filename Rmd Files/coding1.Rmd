---
title: "CS598: Practical Statistical Learning Coding Assignment #1"
output: html_document
---

### Group Members: Derek Chapman and Zeed Jarrah

#### Helper Functions

<em>
  1) Generate the training and test data  
  2) Obtain the Cross-Validation error rate for a single k  
  3) Determine the best k for a given dataset (kmeans)   
  4) Evaluate a mixture of normal with 10 components  
</em>

```{r}
library(class)

generate_samples = function(s = 1, num_train = 200, num_test = 10000){
  num_centers = 10
  p = 2
  s = 1
  
  #distribution 'centers'
  m1 = matrix(rnorm(num_centers*p), num_centers, p) * s + cbind(rep(1, num_centers), rep(0, num_centers))
  m0 = matrix(rnorm(num_centers*p), num_centers, p) * s + cbind(rep(0, num_centers), rep(1, num_centers))
  
  s = sqrt(1/5)
  
  #training data
  id1 = sample(1:num_centers, num_train, replace = T)
  id0 = sample(1:num_centers, num_train, replace = T)
  train_data = matrix(rnorm(2*num_train*p), 2*num_train, p)*s  + rbind(m1[id1, ], m0[id0, ])
  Ytrain = factor(c(rep(1, num_train), rep(0, num_train)))
  train = as.data.frame(cbind(Ytrain, train_data))
  
  #testing data
  id1 = sample(1:num_centers, num_test, replace = T)
  id0 = sample(1:num_centers, num_test, replace = T)
  test_data = matrix(rnorm(2*num_test*p), 2*num_test, p)*s + rbind(m1[id1, ], m0[id0, ])
  Ytest = factor(c(rep(1, num_test), rep(0, num_test)))
  test = as.data.frame(cbind(Ytest, test_data))
  samples = list(train = train, test = test, m0 = m0, m1 = m1)
  }

#get cross-validated error rate for a single k value
get_cv_k_err = function(data, Y, k_val, folds = 10){
  error = 0
  fold_size = floor(nrow(data)/folds)
  
  for(fold in 1:folds){
    #create our folds (split train/test data)
    testset_index = ((fold - 1)*fold_size + 1) : (fold*fold_size)
    trainX = data[-testset_index, ]
    trainY = Y[-testset_index]
    testX = data[testset_index, ]
    testY = Y[testset_index]
    
    predY = knn(trainX, testX, trainY, k = k_val)
    error = error + sum(testY != predY)
  }
  error = error/nrow(data)
}

#get the best k size for a given data/response set
get_best_k = function(data, Y, folds = 10){
  fold_size = floor(nrow(data)/folds)
  ks = seq(1, nrow(data) - fold_size, 2) 
  cv_k_err_rates = rep(0, length(ks))  

  #get error rates for all k values
  for(k_i in 1:length(ks)){
    cv_k_err_rates[k_i] = get_cv_k_err(data, Y, ks[k_i], folds)
  }
  
  #return best k value based on lowest error
  max(ks[cv_k_err_rates == min(cv_k_err_rates)])
}

#determine most likely cluster the point is from
mixnorm = function(x, m0, m1){
  sum(exp(-apply((t(m1)-x)^2, 2, sum) * 5/2)) / sum(exp(-apply((t(m0)-x)^2, 2, sum) * 5/2))
  }


plot_samples = function(dataset){
  xr = range(dataset[, 2])
  yr = range(dataset[, 3])
  # yr = range(samples$train$Ytrain, samples$test$Ytest)
  color = rep(NA, nrow(dataset))
  color[which(dataset[, 1] == 2)] = 'red'
  color[which(dataset[, 1] == 1)] = 'blue'
  
  plot(xr, yr, type = "n", xlab = "X2", ylab = "X3")
  points(dataset[, 2], dataset[, 3],
         col = color,
         pch = 20,
         cex = .5)
  }


```

<em>
 
 Initialize the seed and create a data frame that will hold the training and test error for the following four procedures:  
 1. Linear regression with cut-off value^2^ 0.5  
 2. Quadratic regression with cut-off value 0.5  
 3. kNN classification with k chosen by 10-fold cross validation  
 4. Bayes rule  
 
</em>

```{r seed}
#repeat process 20x
seed = 0721
set.seed(seed)

sims = 20
best_ks = rep(0, sims)
err = data.frame(
  slr.train  = rep(0, sims),
  slr.test   = rep(0, sims),
  quad.train = rep(0, sims),
  quad.test  = rep(0, sims),
  knn.train  = rep(0, sims),
  knn.test   = rep(0, sims),
  bayes.train= rep(0, sims),
  bayes.test = rep(0, sims)
  )
```

<em>
A training set and test set of size 200 and 10,000 respectively, are initialized.   
The training set is then fitted individually to each of the four procedures highlighted above to create four different models.
Each of the models is then used to predict the labels [0,1] on each sample in the test set. 
</em>

```{r main}
for(i in 1:sims){
  print(paste("on sim", i))
  samples = generate_samples()
  trainX = samples$train[c("V2", "V3")]
  trainY = samples$train$Ytrain - 1
  testX  = samples$test[c("V2", "V3")]
  testY  = samples$test$Ytest - 1
 
  #slr -- train
  slr_mdl = lm(as.numeric(Ytrain) - 1 ~ ., data = samples$train)
  slr_train_pred   = as.numeric(slr_mdl$fitted.values > 0.5)
  err$slr.train[i] = sum(slr_train_pred != trainY) / nrow(samples$train)
  
  #slr -- test 
  slr_test_pred   = ifelse(predict(slr_mdl, newdata = samples$test) > 0.5, 1, 0)
  err$slr.test[i] = sum(slr_test_pred != testY) / nrow(samples$test)

  #quadratic -- train
  quadratic_mdl     = lm((as.numeric(Ytrain) - 1) ~ V2 + V3 + I(V2*V3) + I(V2^2) + I(V3^2), data = samples$train)
  quad_train_pred   = as.numeric(quadratic_mdl$fitted.values > 0.5)
  err$quad.train[i] = sum(quad_train_pred != trainY) / nrow(samples$train)
  
  #quadratic test data
  quad_test_pred   = ifelse(predict(quadratic_mdl, newdata = samples$test) > 0.5, 1, 0)
  err$quad.test[i] = sum(quad_test_pred != testY) / nrow(samples$test)
  
  #knn
  best_ks[i] = get_best_k(trainX, trainY, 10)
  #knn train
  train_pred = knn(trainX, trainX, trainY, k = best_ks[i])
  err$knn.train[i] = sum(train_pred != trainY) / nrow(samples$train)
  #knn test
  test_pred = knn(trainX, testX, trainY, k = best_ks[i])
  err$knn.test[i] = sum(test_pred != testY) / nrow(samples$test)
  
  #bayes error train
  traindata = samples$train[c("V2", "V3")]
  bayes_train_pred = apply(traindata, 1, mixnorm, m0 = samples$m0, m1 = samples$m1)
  bayes_train_pred = as.numeric(bayes_train_pred > 1)
  err$bayes.train[i] = sum(bayes_train_pred != (samples$train$Ytrain-1)) / nrow(samples$train)
  
  #bayes error test
  testdata = samples$test[c("V2", "V3")]
  bayes_test_pred = apply(testdata, 1, mixnorm, m0 = samples$m0, m1 = samples$m1)
  bayes_test_pred = as.numeric(bayes_test_pred > 1)
  err$bayes.test[i] = sum(bayes_test_pred != (samples$test$Ytest-1)) / nrow(samples$test)  
  }
```

<em>
After iterating 20 times for each model, the results are plotted and summarized. The plots of the linear and quadratic models include
the decision boundary  to better illustrate the model's equation. When examining the error rates of the four methods, the linear model generally
performed worse than the other three procedures. Quadratic regression did not offer a significant improvement on the test data set. The k-Nearest Neighbors classifier was 
considerably less erroneous on the training data but this did not translate over to the test data set. In terms of overall performance, the Bayes classifier had a higher error rate on the training set than k-NN but achieves the lowest error rate on the test data set among all the procedures implemented.

</em>

```{r slr_plot}
#plot SLR + line
plot_samples(samples$train)
grid()
title(main = "Linear Model with Decision Boundary")
legend('bottomleft', 
       c("Class 1", "Class 0"),
       col = c("Red", "Blue"),
       bty = "a",
       pch = 19,
       pt.cex = .75,
       horiz = F, 
       inset = c(0.1, 0.1))
slope = -slr_mdl$coef[[2]] / slr_mdl$coef[[3]]
intercept = (0.5 - slr_mdl$coef[[1]]) / slr_mdl$coef[[3]]
abline(a=intercept, b=slope, lwd = 2, lty = 3)

#plot quadratic + line
plot(samples$train)
grid()
title(main = "Quadratic Model with Decision Boundary")
quadratic_mdl$coefficients

#train/test error for all methods
colors = c("mediumblue", "darkorange2")
x_labels = c("SLR", "Quadratic LM", "kNN", "Bayes")
boxplot(err,
        ylab = "Error Rates",
        xaxt = "none",
        col = colors,
        main = "Simulating Train/Tes Error with Various Methods")
legend('bottomright', 
       c("Training Data", "Testing Data"),
       col = colors,
       bty = "a",
       pch = 19,
       pt.cex = .75,
       horiz = F, 
       inset = c(0.1, 0.1))
axis(1, at = c(1.5, 3.5, 5.5, 7.5), labels = x_labels)

#best k values with mean and sd range
{
plot(best_ks, 
     main = "Chosen k Value for kNN Method",
     xlab = "Iteration",
     ylab = "k",
     col = "dodgerblue", pch = 19)
# grid()
lines(best_ks, lty = 3)
abline(h = mean(best_ks), lty = 4, col = "darkgreen")
m = mean(best_ks)
s = sd(best_ks)
# mtext("Mean", 1, at = 3, padj = -10)
x0 = 0; x1 = 100
y0 = m - (s/2)
y1 = m + (s/2)
rect(x0, y0, x1, y1, col = rgb(0.1, 0.1, 0.9, alpha = 0.2))
}

```